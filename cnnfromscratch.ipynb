{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6e5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator #array_to_img, img_to_array, load_img\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52f686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in our model we use augmentation,dropout,fewer layers and fewer filters to avoid overfit\n",
    "#dropout because of augmentation our model can see same image twice\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3))) #for tensorflow we modified from example\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#the model so far outputs 3D feature maps(height, width, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7974f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 34, 34, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1183808   \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten()) #this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb8bc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "#this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)\n",
    "\n",
    "#This is the augmentation configuration we will use for testing:\n",
    "#Only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#This is a generator that will read picturs found in \n",
    "#subfolders of 'data/train', and indefinitely generate\n",
    "#batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory('Data/Train', #this is the target directory\n",
    "                                                   target_size=(150, 150), #all images will be resized to 150*150\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='binary') #since we use binary_crossentropy,loss we need binary labels\n",
    "#this is a similar generator for test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Data/Test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393815fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "125/125 [==============================] - 60s 479ms/step - loss: 0.6461 - accuracy: 0.6460 - val_loss: 0.6189 - val_accuracy: 0.6719\n",
      "Epoch 2/25\n",
      "125/125 [==============================] - 63s 505ms/step - loss: 0.6105 - accuracy: 0.6705 - val_loss: 0.6159 - val_accuracy: 0.6719\n",
      "Epoch 3/25\n",
      "125/125 [==============================] - 58s 463ms/step - loss: 0.6066 - accuracy: 0.6720 - val_loss: 0.5957 - val_accuracy: 0.6836\n",
      "Epoch 4/25\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.5699 - accuracy: 0.7085 - val_loss: 0.5993 - val_accuracy: 0.6719\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - 61s 488ms/step - loss: 0.5596 - accuracy: 0.7205 - val_loss: 0.6124 - val_accuracy: 0.7188\n",
      "Epoch 6/25\n",
      "125/125 [==============================] - 59s 469ms/step - loss: 0.5526 - accuracy: 0.7300 - val_loss: 0.6018 - val_accuracy: 0.6758\n",
      "Epoch 7/25\n",
      "125/125 [==============================] - 59s 469ms/step - loss: 0.5466 - accuracy: 0.7355 - val_loss: 0.6027 - val_accuracy: 0.7227\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - 61s 484ms/step - loss: 0.5249 - accuracy: 0.7530 - val_loss: 0.6054 - val_accuracy: 0.6914\n",
      "Epoch 9/25\n",
      "125/125 [==============================] - 59s 471ms/step - loss: 0.5269 - accuracy: 0.7475 - val_loss: 0.5924 - val_accuracy: 0.7070\n",
      "Epoch 10/25\n",
      "125/125 [==============================] - 59s 473ms/step - loss: 0.5121 - accuracy: 0.7560 - val_loss: 0.5877 - val_accuracy: 0.7227\n",
      "Epoch 11/25\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.4869 - accuracy: 0.7770 - val_loss: 0.6561 - val_accuracy: 0.7148\n",
      "Epoch 12/25\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.4774 - accuracy: 0.7760 - val_loss: 0.6163 - val_accuracy: 0.6602\n",
      "Epoch 13/25\n",
      "125/125 [==============================] - 61s 484ms/step - loss: 0.4664 - accuracy: 0.7720 - val_loss: 0.5378 - val_accuracy: 0.7461\n",
      "Epoch 14/25\n",
      "125/125 [==============================] - 59s 471ms/step - loss: 0.4837 - accuracy: 0.7725 - val_loss: 0.5337 - val_accuracy: 0.7383\n",
      "Epoch 15/25\n",
      "125/125 [==============================] - 59s 468ms/step - loss: 0.4477 - accuracy: 0.8015 - val_loss: 0.5616 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "125/125 [==============================] - 59s 468ms/step - loss: 0.4399 - accuracy: 0.8020 - val_loss: 0.5597 - val_accuracy: 0.7617\n",
      "Epoch 17/25\n",
      "125/125 [==============================] - 63s 504ms/step - loss: 0.4574 - accuracy: 0.8085 - val_loss: 0.5617 - val_accuracy: 0.7383\n",
      "Epoch 18/25\n",
      "125/125 [==============================] - 64s 512ms/step - loss: 0.4419 - accuracy: 0.8005 - val_loss: 0.5586 - val_accuracy: 0.7305\n",
      "Epoch 19/25\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.4281 - accuracy: 0.8030 - val_loss: 0.5899 - val_accuracy: 0.7617\n",
      "Epoch 20/25\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.4163 - accuracy: 0.8190 - val_loss: 0.5284 - val_accuracy: 0.7773\n",
      "Epoch 21/25\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.4129 - accuracy: 0.8130 - val_loss: 0.7943 - val_accuracy: 0.7344\n",
      "Epoch 22/25\n",
      "125/125 [==============================] - 59s 470ms/step - loss: 0.4321 - accuracy: 0.8130 - val_loss: 0.5610 - val_accuracy: 0.7266\n",
      "Epoch 23/25\n",
      "125/125 [==============================] - 60s 476ms/step - loss: 0.4209 - accuracy: 0.8210 - val_loss: 0.5499 - val_accuracy: 0.7617\n",
      "Epoch 24/25\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 0.4053 - accuracy: 0.8165 - val_loss: 0.6140 - val_accuracy: 0.7031\n",
      "Epoch 25/25\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.4087 - accuracy: 0.8180 - val_loss: 0.5738 - val_accuracy: 0.7461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f156ea1940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=2000 // batch_size,\n",
    "                         epochs=25,validation_data=test_generator,validation_steps=256 // batch_size)\n",
    "#model.fit(\n",
    "    #train_generator,\n",
    "    #steps_per_epoch=2000 // batch_size,\n",
    "    #epochs=10,val_data=test_generator,\n",
    "    #val_steps=256 // batch_size)\n",
    "#model.save_weights('first_try.h5') #always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9344f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
